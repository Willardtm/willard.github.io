<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>TensorFlow 2.0 使用指南 (2020.4.27更新图片数据处理块) | Klaus&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="前后大概花了一周半的时间把TensorFlow2.0的框架学完，这个版本相较于1.0在代码上要更加易于理解和操作。所以这里用这篇博客来记录 TensorFlow 2.0 中的各种操作细节，算是个人备忘录版的使用指南吧。">
<meta name="keywords" content="NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow 2.0 使用指南 (2020.4.27更新图片数据处理块)">
<meta property="og:url" content="http://yoursite.com/2020/04/26/TensorFlow-2-0-使用指南/index.html">
<meta property="og:site_name" content="Klaus&#39;s Blog">
<meta property="og:description" content="前后大概花了一周半的时间把TensorFlow2.0的框架学完，这个版本相较于1.0在代码上要更加易于理解和操作。所以这里用这篇博客来记录 TensorFlow 2.0 中的各种操作细节，算是个人备忘录版的使用指南吧。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/26/Jcvy34.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/26/J2tlWt.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/26/J2dvVS.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/26/JRAVmT.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/JhfbUe.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/JhhmrV.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/Jhh82R.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/Jh4lef.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/Jh4ayq.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/04/28/Jh46fJ.png">
<meta property="og:updated_time" content="2020-04-27T16:38:15.305Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow 2.0 使用指南 (2020.4.27更新图片数据处理块)">
<meta name="twitter:description" content="前后大概花了一周半的时间把TensorFlow2.0的框架学完，这个版本相较于1.0在代码上要更加易于理解和操作。所以这里用这篇博客来记录 TensorFlow 2.0 中的各种操作细节，算是个人备忘录版的使用指南吧。">
<meta name="twitter:image" content="https://s1.ax1x.com/2020/04/26/Jcvy34.png">
  
    <link rel="alternate" href="/atom.xml" title="Klaus&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Klaus&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">MIA SAN MIA</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Suche"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-TensorFlow-2-0-使用指南" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/04/26/TensorFlow-2-0-使用指南/" class="article-date">
  <time datetime="2020-04-26T06:06:19.000Z" itemprop="datePublished">2020-04-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      TensorFlow 2.0 使用指南 (2020.4.27更新图片数据处理块)
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
	  <!-- Table of Contents -->
		
		  <div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据预处理"><span class="toc-number">1.</span> <span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#tf框架自带的数据集"><span class="toc-number">1.1.</span> <span class="toc-text">tf框架自带的数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sklearn自带的数据集"><span class="toc-number">1.2.</span> <span class="toc-text">sklearn自带的数据集</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据加载和预处理"><span class="toc-number">2.</span> <span class="toc-text">数据加载和预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#csv数据处理"><span class="toc-number">2.1.</span> <span class="toc-text">csv数据处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#x-label处理方式一：tf-data-experimental-make-csv-dataset"><span class="toc-number">2.1.1.</span> <span class="toc-text">x,label处理方式一：tf.data.experimental.make_csv_dataset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#x-label处理方式二-pandas"><span class="toc-number">2.1.2.</span> <span class="toc-text">x,label处理方式二:pandas</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#离散型特征"><span class="toc-number">2.1.3.</span> <span class="toc-text">离散型特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#连续型数据处理"><span class="toc-number">2.1.4.</span> <span class="toc-text">连续型数据处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#创建预处理层"><span class="toc-number">2.1.5.</span> <span class="toc-text">创建预处理层</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型构建，训练与评估"><span class="toc-number">2.2.</span> <span class="toc-text">模型构建，训练与评估</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#tf处理数据版泰坦尼克生存预测模型完整代码"><span class="toc-number">2.2.1.</span> <span class="toc-text">tf处理数据版泰坦尼克生存预测模型完整代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pandas处理数据版泰坦尼克生存预测模型完整代码"><span class="toc-number">2.2.2.</span> <span class="toc-text">pandas处理数据版泰坦尼克生存预测模型完整代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#总结"><span class="toc-number">2.2.3.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#numpy数据预处理"><span class="toc-number">2.3.</span> <span class="toc-text">numpy数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#图像数据处理"><span class="toc-number">2.4.</span> <span class="toc-text">图像数据处理</span></a></li></ol></li></ol>
		  </div>
		
        <p>前后大概花了一周半的时间把TensorFlow2.0的框架学完，这个版本相较于1.0在代码上要更加易于理解和操作。<br>所以这里用这篇博客来记录 TensorFlow 2.0 中的各种操作细节，算是个人备忘录版的使用指南吧。<br><a id="more"></a></p>
<p>本篇博客会按照数据处理，Estimator，模型保存，CNN及其实践，RNN及其实践，注意力机制等几个部分来撰写。<br>p.s. 以前开发做点Python相关的东西还是习惯用Pycharm，不过学习这个框架的过程中由于需要清晰的看到每个步骤的结果，所以用了一下Jupyter，害，用户体验嘛，那当然是极好的！以后做神经网络模型这类型的，我可能会继续沿用Jupyter，不过如果项目规模偏大，那还是回到Pycharm。btw,VScode编写ipynb体验还不错。</p>
<p><b>注：本篇博客参考内容主要来自于<a href="https://www.tensorflow.org/tutorials?hl=zh-cn" target="_blank" rel="noopener">TF2.1.0官网的教程</a>，部分内容有参考相关学习过的内容，结合这二者写完这篇笔记。</b></p>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>以我个人的看法，数据预处理这部分内容在神经网络的构建中可以说是极其重要的。如果没有处理好数据，并生成用以训练的向量，那这个模型基本白搭，所以这块的内容我会尽量去详细的记录。</p>
<h3 id="tf框架自带的数据集"><a href="#tf框架自带的数据集" class="headerlink" title="tf框架自带的数据集"></a>tf框架自带的数据集</h3><p>tf框架最常见的自带数据集包括：mnist,fashion_minist，imbd等，这类数据集最大的好处就是自带切分功能。<br>引用方式通常比较简单，并且已经是向量化的数据，以这里取出来的数据来说，就是一张大小为28x28的图像各个像素点的值。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"><span class="keyword">from</span> tensorflow import keras</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接获取数据</span></span><br><span class="line"><span class="attribute">mnist</span>=keras.datasets.mnist</span><br><span class="line">(x_train_all,y_train_all),(x_test,y_test)=mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切分训练集和验证集</span></span><br><span class="line">x_train,<span class="attribute">y_train</span>=x_train_all[:5000],y_train_all[:5000]</span><br><span class="line">x_valid,<span class="attribute">y_valid</span>=x_train_all[5000:],y_train_all[5000:]</span><br></pre></td></tr></table></figure></p>
<h3 id="sklearn自带的数据集"><a href="#sklearn自带的数据集" class="headerlink" title="sklearn自带的数据集"></a>sklearn自带的数据集</h3><p>sklearn下的数据集类似于tf下面的，不过需要额外引入另外的两个包，一个负责取出数据集，一个负责对训练集和测试集进行分割。<br><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line">from sklearn.datasets <span class="keyword">import</span> fetch_california_housing # 取出数据集</span><br><span class="line">from sklearn.model_selection <span class="keyword">import</span> train_test_split # 对数据集进行分割</span><br><span class="line"></span><br><span class="line"># 取出相应的数据集</span><br><span class="line">housing=fetch_california_housing()</span><br><span class="line"></span><br><span class="line"># 打印出相关信息</span><br><span class="line"><span class="built_in">print</span>(housing.DESCR) # 数据描述</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'----------------'</span>)</span><br><span class="line"><span class="built_in">print</span>(housing.<span class="keyword">data</span>.<span class="built_in">shape</span>) # 数据大小</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'----------------'</span>)</span><br><span class="line"><span class="built_in">print</span>(housing.<span class="keyword">target</span>.<span class="built_in">shape</span>) # label</span><br><span class="line"></span><br><span class="line">x_train_all, x_test, y_train_all, y_test = train_test_split(</span><br><span class="line">    housing.<span class="keyword">data</span>, housing.<span class="keyword">target</span>, random_state = <span class="number">7</span>)</span><br><span class="line">x_train, x_valid, y_train, y_valid = train_test_split(</span><br><span class="line">    x_train_all, y_train_all, random_state = <span class="number">11</span>)</span><br><span class="line"><span class="built_in">print</span>(x_train.<span class="built_in">shape</span>, y_train.<span class="built_in">shape</span>)</span><br><span class="line"><span class="built_in">print</span>(x_valid.<span class="built_in">shape</span>, y_valid.<span class="built_in">shape</span>)</span><br><span class="line"><span class="built_in">print</span>(x_test.<span class="built_in">shape</span>, y_test.<span class="built_in">shape</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="数据加载和预处理"><a href="#数据加载和预处理" class="headerlink" title="数据加载和预处理"></a>数据加载和预处理</h2><p>以我过去从事NLP文本分类的经验，单从上面两个包中提供的数据集不满足实验需求，不同的文章中使用到的数据集不一样，所以还需要具备处理其他数据集的能力。</p>
<h3 id="csv数据处理"><a href="#csv数据处理" class="headerlink" title="csv数据处理"></a>csv数据处理</h3><h4 id="x-label处理方式一：tf-data-experimental-make-csv-dataset"><a href="#x-label处理方式一：tf-data-experimental-make-csv-dataset" class="headerlink" title="x,label处理方式一：tf.data.experimental.make_csv_dataset"></a>x,label处理方式一：tf.data.experimental.make_csv_dataset</h4><p>这里直接使用这俩数据集（泰坦尼克号生存数据集），下载地址如下：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">http<span class="variable">s:</span>//storage.googleapis.<span class="keyword">com</span>/<span class="keyword">tf</span>-datasets/titanic/train.csv</span><br><span class="line">http<span class="variable">s:</span>//storage.googleapis.<span class="keyword">com</span>/<span class="keyword">tf</span>-datasets/titanic/<span class="built_in">eval</span>.csv</span><br></pre></td></tr></table></figure></p>
<p>下载下来以后单独保存在一个 dataset 文件夹下面，下载完成以后，有两种方法可以查看csv中数据集包含的数据：<br><b>1. 使用pandas</b><br>关于pandas部分库的操作，之前我写过一篇笔记，可以作为参考：<a href="http://klausvon.cn/2018/10/05/Python-%E8%AF%BB%E5%86%99csv%E6%96%87%E4%BB%B6%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/" target="_blank" rel="noopener">Python 读写csv文件相关操作</a></p>
<p>这里直接取出列表名称,和相关数据<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">file</span>=pd.read_csv(<span class="string">'./dataset/train.csv'</span>)</span><br><span class="line"><span class="keyword">print</span>(<span class="keyword">list</span>(<span class="keyword">file</span>.head()))#列表名称</span><br><span class="line"><span class="keyword">print</span>(<span class="keyword">file</span>.head())#列表数据</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/26/Jcvy34.png" alt=""></p>
<p><b>2. 直接在Jupyter的环境下查看</b><br><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="addition">!head &#123;文件路径&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>这些取出来的列名参数需要传参给tf.data.experimental.make_csv_dataset下面的column_names参数。<br>使用这个包和取出的列名来构造可以用于基于TensorFlow搭建模型的训练和测试数据。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">file_path=<span class="string">'./dataset/train.csv'</span></span><br><span class="line">file=pd.read_csv(file_path)</span><br><span class="line">csv_columns=list(file.head())</span><br><span class="line">print(csv_columns)<span class="comment">#列表名称</span></span><br><span class="line">print(file.head())<span class="comment">#列表数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 label</span></span><br><span class="line">label_culomn=<span class="string">'survived'</span></span><br><span class="line">labels=[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dataset</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    dataset=tf.data.experimental.make_csv_dataset(</span><br><span class="line">        file_path,</span><br><span class="line">        batch_size=<span class="number">12</span>,</span><br><span class="line">        label_name=label_culomn,<span class="comment"># 取出某列的数据作为label</span></span><br><span class="line">        na_value=<span class="string">'?'</span>,<span class="comment"># 识别NA/NaN的附加字符串,设置为?</span></span><br><span class="line">        num_epochs=<span class="number">1</span>,<span class="comment"># 遍历数据集的次数</span></span><br><span class="line">        ignore_errors=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成的值类型为:</span></span><br><span class="line"><span class="comment"># &lt;class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'&gt;</span></span><br><span class="line"><span class="comment"># 如果想查看其中的内容,可以使用iter进行迭代,通过next嵌套iter可以查看第一轮运行的数据</span></span><br><span class="line"><span class="comment"># 第一轮运行数据的大小取决于设置的batch_size</span></span><br><span class="line">raw_train_data=get_dataset(file_path) </span><br><span class="line">raw_test_data=get_dataset(file_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的数据集中的样本和标签</span></span><br><span class="line">example,label=next(iter(raw_train_data))</span><br><span class="line">print(<span class="string">'Example:'</span>,example) <span class="comment"># sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone</span></span><br><span class="line">print(<span class="string">'Label:'</span>,label) <span class="comment"># label:survived</span></span><br></pre></td></tr></table></figure></p>
<p>输出值如下：<br><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Example:OrderedDict([(<span class="string">'sex'</span>, &lt;tf.Tensor: shape=(<span class="number">12</span>,), dtype=<span class="keyword">string</span>, numpy=</span><br><span class="line"><span class="keyword">array</span>([b<span class="string">'male'</span>, b<span class="string">'female'</span>, b<span class="string">'male'</span>, b<span class="string">'male'</span>, b<span class="string">'male'</span>, b<span class="string">'female'</span>, b<span class="string">'male'</span>,</span><br><span class="line">       b<span class="string">'male'</span>, b<span class="string">'female'</span>, b<span class="string">'male'</span>, b<span class="string">'male'</span>, b<span class="string">'female'</span>], dtype=<span class="keyword">object</span>)&gt;), (<span class="string">'age'</span>, &lt;tf.Tensor: shape=(<span class="number">12</span>,), dtype=float32, numpy=</span><br><span class="line"><span class="keyword">array</span>([<span class="number">28</span>. , <span class="number">28</span>. , <span class="number">21</span>. , <span class="number">26</span>. , <span class="number">45</span>. , <span class="number">31</span>. , <span class="number">28</span>. , <span class="number">18</span>. , <span class="number">28</span>. , <span class="number">43</span>. , <span class="number">32.5</span>,</span><br><span class="line">       <span class="number">58</span>. ], dtype=float32)&gt;), (<span class="string">'n_siblings_spouses'</span>, &lt;tf.Tensor: shape=(<span class="number">12</span>,), dtype=int32, numpy=<span class="keyword">array</span>([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])&gt;), (<span class="string">'parch'</span>, &lt;tf.Tensor: shape=(<span class="number">12</span>,), dtype=int32, numpy=<span class="keyword">array</span>([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])&gt;), (<span class="string">'fare'</span>, &lt;tf.Tensor: shape=(<span class="number">12</span>,), dtype=float32, numpy=</span><br><span class="line"><span class="keyword">array</span>([ <span class="number">35.5</span>   , <span class="number">133.65</span>  ,  <span class="number">73.5</span>   ,   <span class="number">8.05</span>  ,   <span class="number">8.05</span>  , <span class="number">164.8667</span>,</span><br><span class="line">        <span class="number">56.4958</span>,   <span class="number">7.7958</span>,  <span class="number">14.4542</span>,  <span class="number">26.25</span>  ,  <span class="number">30.0708</span>, <span class="number">153.4625</span>],</span><br><span class="line">      dtype=float32)&gt;), (<span class="string">'class'</span>, &lt;tf.Tensor: shape=(<span class="number">12</span>,), dtype=<span class="keyword">string</span>, numpy=</span><br><span class="line"><span class="keyword">array</span>([b<span class="string">'First'</span>, b<span class="string">'First'</span>, b<span class="string">'Second'</span>, b<span class="string">'Third'</span>, b<span class="string">'Third'</span>, b<span class="string">'First'</span>,</span><br><span class="line">       b<span class="string">'Third'</span>, b<span class="string">'Third'</span>, b<span class="string">'Third'</span>, b<span class="string">'Second'</span>, b<span class="string">'Second'</span>, b<span class="string">'First'</span>],</span><br><span class="line">      dtype=<span class="keyword">object</span>)&gt;), (<span class="string">'deck'</span>, &lt;tf.Tensor: shape=(<span class="number">12</span>,), dtype=<span class="keyword">string</span>, numpy=</span><br><span class="line"><span class="keyword">array</span>([b<span class="string">'A'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'C'</span>,</span><br><span class="line">       b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'unknown'</span>, b<span class="string">'C'</span>],</span><br><span class="line">      dtype=<span class="keyword">object</span>)&gt;), (<span class="string">'embark_town'</span>, &lt;tf.Tensor: shape=(<span class="number">12</span>,), dtype=<span class="keyword">string</span>, numpy=</span><br><span class="line"><span class="keyword">array</span>([b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>,</span><br><span class="line">       b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>, b<span class="string">'Southampton'</span>,</span><br><span class="line">       b<span class="string">'Cherbourg'</span>, b<span class="string">'Southampton'</span>, b<span class="string">'Cherbourg'</span>, b<span class="string">'Southampton'</span>],</span><br><span class="line">      dtype=<span class="keyword">object</span>)&gt;), (<span class="string">'alone'</span>, &lt;tf.Tensor: shape=(<span class="number">12</span>,), dtype=<span class="keyword">string</span>, numpy=</span><br><span class="line"><span class="keyword">array</span>([b<span class="string">'y'</span>, b<span class="string">'n'</span>, b<span class="string">'y'</span>, b<span class="string">'y'</span>, b<span class="string">'y'</span>, b<span class="string">'n'</span>, b<span class="string">'y'</span>, b<span class="string">'y'</span>, b<span class="string">'n'</span>, b<span class="string">'n'</span>, b<span class="string">'n'</span>,</span><br><span class="line">       b<span class="string">'n'</span>], dtype=<span class="keyword">object</span>)&gt;)])</span><br><span class="line"><span class="keyword">Label</span>:tf.Tensor([<span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>], shape=(<span class="number">12</span>,), dtype=int32)</span><br></pre></td></tr></table></figure></p>
<p>这里有个问题，如何单独查看example或者label中的值，这个很简单，这两个值类似于字典类型，以example举例子，取出age这一栏，并通过numpy形式展示：<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="name">example</span>['age'].numpy())</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/26/J2tlWt.png" alt=""></p>
<h4 id="x-label处理方式二-pandas"><a href="#x-label处理方式二-pandas" class="headerlink" title="x,label处理方式二:pandas"></a>x,label处理方式二:pandas</h4><p>基于pandas读取出来的csv文件可以直接使用pop函数来取出某个单独列的值。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">train_df=pd.read_csv(<span class="string">'./dataset/train.csv'</span>)</span><br><span class="line">eval_df=pd.read_csv(<span class="string">'./dataset/eval.csv'</span>)</span><br><span class="line"></span><br><span class="line">y_train=train_df.pop(<span class="string">'survived'</span>)</span><br><span class="line">y_eval=eval_df.pop(<span class="string">'survived'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'train_df.shape:'</span>,train_df.shape)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'eval_df.shape:'</span>,eval_df.shape)</span></span></span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/26/J2dvVS.png" alt=""></p>
<p>pandas在划分x和y的时候相对比之前tf.data.experimental.make_csv_dataset要简便不少，同时，取出的pandas Series数据可以在外嵌套一层numpy.array()就可以转换为numpy类型的array,然后通过reshape转换成模型需要的任意大小：<br><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="title">new_train_df</span>=np.array(train_df).reshape([<span class="number">-1</span>,])</span><br></pre></td></tr></table></figure></p>
<h4 id="离散型特征"><a href="#离散型特征" class="headerlink" title="离散型特征"></a>离散型特征</h4><p>上面介绍了两种对数据进行划分的方法，下面继续对数据进行分类。<br>这里直接引用官方文档的话：<br>csv数据中的有些列是分类的列，也就是说，这些列只能在有限的集合中取值。(这些列也就相当于是已经提取好的特征值)</p>
<p>使用 tf.feature_column API创建一个 tf.feature_column.indicator_column 集合，每个 tf.feature_column.indicator_column对应一个分类的列。</p>
<p>核心api：<br><b><br>tf.feature_column.categorical_column_with_vocabulary_list<br>tf.feature_column.indicator_column<br></b></p>
<figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 这里分类仅使用几个特征列</span><br><span class="line">categories = &#123;</span><br><span class="line">    <span class="string">'sex'</span>: [<span class="string">'male'</span>, <span class="string">'female'</span>],</span><br><span class="line">    <span class="string">'class'</span> : [<span class="string">'First'</span>, <span class="string">'Second'</span>, <span class="string">'Third'</span>],</span><br><span class="line">    <span class="string">'deck'</span> : [<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'D'</span>, <span class="string">'E'</span>, <span class="string">'F'</span>, <span class="string">'G'</span>, <span class="string">'H'</span>, <span class="string">'I'</span>, <span class="string">'J'</span>],</span><br><span class="line">    <span class="string">'embark_town'</span> : [<span class="string">'Cherbourg'</span>, <span class="string">'Southhampton'</span>, <span class="string">'Queenstown'</span>],</span><br><span class="line">    <span class="string">'alone'</span> : [<span class="string">'y'</span>, <span class="string">'n'</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">categorical_columns=[]</span><br><span class="line">for feature,vocab in catecategories.items():</span><br><span class="line">    cat_col=tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        key=feature,</span><br><span class="line">        vocabulary_list=vocab)</span><br><span class="line">    categorical_columns.append(tf.feature_column.indicator_column(cat_col))</span><br><span class="line"></span><br><span class="line">print(categorical_columns)</span><br></pre></td></tr></table></figure>
<h4 id="连续型数据处理"><a href="#连续型数据处理" class="headerlink" title="连续型数据处理"></a>连续型数据处理</h4><p>处理完分类数据之后需要处理连续数据.主要需要进行归一化处理.</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def process_continuous_data(mean,data):</span><br><span class="line">    # 标准化数据</span><br><span class="line">    # <span class="keyword">tf</span>.cas<span class="variable">t:</span>转换数据格式</span><br><span class="line">    data=<span class="keyword">tf</span>.cast(data,<span class="keyword">tf</span>.float32)*<span class="number">1</span>/(<span class="number">2</span>*mean)</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">tf</span>.reshape(data,[-<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">	</span><br><span class="line">MEANS = &#123;</span><br><span class="line">    <span class="string">'age'</span> : <span class="number">29.631308</span>,</span><br><span class="line">    <span class="string">'n_siblings_spouses'</span> : <span class="number">0.545455</span>,</span><br><span class="line">    <span class="string">'parch'</span> : <span class="number">0.379585</span>,</span><br><span class="line">    <span class="string">'fare'</span> : <span class="number">34.385399</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">numerical_columns=[]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature in MEANS.<span class="built_in">keys</span>():</span><br><span class="line">    num_col=<span class="keyword">tf</span>.feature_column.numeric_column(</span><br><span class="line">        feature,</span><br><span class="line">        normalizer_fn=functools.partial(process_continuous_data,MEANS[feature]))</span><br><span class="line">    numerical_columns.<span class="keyword">append</span>(num_col)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span>(numerical_columns)</span><br></pre></td></tr></table></figure>
<p>输出的结果就是各个连续值特征归一化的值:<br><img src="https://s1.ax1x.com/2020/04/26/JRAVmT.png" alt=""></p>
<h4 id="创建预处理层"><a href="#创建预处理层" class="headerlink" title="创建预处理层"></a>创建预处理层</h4><p>上面分别介绍了 离散型特征 和 连续型特征 的处理方法，现在需要对两类型的特征进行合并，从而创建一个能进行预处理的输入层。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">preprocessing_layer = tf<span class="selector-class">.keras</span><span class="selector-class">.layers</span><span class="selector-class">.DenseFeatures</span>(categorical_columns+numerical_columns)</span><br></pre></td></tr></table></figure>
<h3 id="模型构建，训练与评估"><a href="#模型构建，训练与评估" class="headerlink" title="模型构建，训练与评估"></a>模型构建，训练与评估</h3><p>这里暂时先插一句，在tf2.0的版本中，调用构建神经网络中各种层都是使用 tf.keras.layers 来进行构建。<br>同时，由于这是一个Sequential模型，所以要使用 tf.keras.Sequential 方法来创建。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    preprocessing_layer,</span><br><span class="line">    tf.keras.layers.Dense(128,activation=<span class="string">'relu'</span>),<span class="comment"># 基于特征层的基础上构建全连接层</span></span><br><span class="line">    tf.keras.layers.Dense(128,activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(1,activation=<span class="string">'sigmoid'</span>)<span class="comment"># 最后只需要预测一个结果</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    loss=<span class="string">'binary_crossentropy'</span>,<span class="comment"># 定义损失函数</span></span><br><span class="line">    optimizer=<span class="string">'adam'</span>,<span class="comment"># 定义优化器</span></span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])<span class="comment"># 定义衡量结果的标准</span></span><br><span class="line">	</span><br><span class="line">train_data=raw_train_data.shuffle(500) <span class="comment"># 打乱数据</span></span><br><span class="line">test_data=raw_test_data</span><br><span class="line"></span><br><span class="line">model.fit(train_data,epochs=20) <span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line">test_loss, test_accuracy = model.evaluate(test_data) <span class="comment"># 测试模型</span></span><br><span class="line"><span class="built_in">print</span>(test_loss)</span><br><span class="line"><span class="built_in">print</span>(test_accuracy)</span><br></pre></td></tr></table></figure></p>
<h4 id="tf处理数据版泰坦尼克生存预测模型完整代码"><a href="#tf处理数据版泰坦尼克生存预测模型完整代码" class="headerlink" title="tf处理数据版泰坦尼克生存预测模型完整代码"></a>tf处理数据版泰坦尼克生存预测模型完整代码</h4><p>上面为了分步描述步骤，写得比较简略，这里贴上一个完整版以供参考。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"></span><br><span class="line">file_path=<span class="string">'./dataset/train.csv'</span></span><br><span class="line">file=pd.read_csv(file_path)</span><br><span class="line">csv_columns=list(file.head())</span><br><span class="line">print(csv_columns)<span class="comment">#列表名称</span></span><br><span class="line">print(file.head())<span class="comment">#列表数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 label</span></span><br><span class="line">label_culomn=<span class="string">'survived'</span></span><br><span class="line">labels=[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dataset</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    dataset=tf.data.experimental.make_csv_dataset(</span><br><span class="line">        file_path,</span><br><span class="line">        batch_size=<span class="number">12</span>,</span><br><span class="line">        label_name=label_culomn,<span class="comment"># 取出某列的数据作为label</span></span><br><span class="line">        na_value=<span class="string">'?'</span>,<span class="comment"># 识别NA/NaN的附加字符串,设置为?</span></span><br><span class="line">        num_epochs=<span class="number">1</span>,<span class="comment"># 遍历数据集的次数</span></span><br><span class="line">        ignore_errors=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成的值类型为:</span></span><br><span class="line"><span class="comment"># &lt;class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'&gt;</span></span><br><span class="line"><span class="comment"># 如果想查看其中的内容,可以使用iter进行迭代,通过next嵌套iter可以查看第一轮运行的数据</span></span><br><span class="line"><span class="comment"># 第一轮运行数据的大小取决于设置的batch_size</span></span><br><span class="line">raw_train_data=get_dataset(file_path) </span><br><span class="line">raw_test_data=get_dataset(file_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生成的数据集中的样本和标签</span></span><br><span class="line">example,label=next(iter(raw_train_data))</span><br><span class="line">print(<span class="string">'Example:'</span>,example) <span class="comment"># sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone</span></span><br><span class="line">print(<span class="string">'Label:'</span>,label) <span class="comment"># label:survived</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理离散型特征</span></span><br><span class="line">categories = &#123;</span><br><span class="line">    <span class="string">'sex'</span>: [<span class="string">'male'</span>, <span class="string">'female'</span>],</span><br><span class="line">    <span class="string">'class'</span> : [<span class="string">'First'</span>, <span class="string">'Second'</span>, <span class="string">'Third'</span>],</span><br><span class="line">    <span class="string">'deck'</span> : [<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'D'</span>, <span class="string">'E'</span>, <span class="string">'F'</span>, <span class="string">'G'</span>, <span class="string">'H'</span>, <span class="string">'I'</span>, <span class="string">'J'</span>],</span><br><span class="line">    <span class="string">'embark_town'</span> : [<span class="string">'Cherbourg'</span>, <span class="string">'Southhampton'</span>, <span class="string">'Queenstown'</span>],</span><br><span class="line">    <span class="string">'alone'</span> : [<span class="string">'y'</span>, <span class="string">'n'</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">categorical_columns=[]</span><br><span class="line"><span class="keyword">for</span> feature,vocab <span class="keyword">in</span> catecategories.items():</span><br><span class="line">    cat_col=tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">        key=feature,</span><br><span class="line">        vocabulary_list=vocab)</span><br><span class="line">    categorical_columns.append(tf.feature_column.indicator_column(cat_col))</span><br><span class="line"></span><br><span class="line">print(categorical_columns)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_continuous_data</span><span class="params">(mean,data)</span>:</span></span><br><span class="line">    <span class="comment"># 标准化数据</span></span><br><span class="line">    <span class="comment"># tf.cast:转换数据格式</span></span><br><span class="line">    data=tf.cast(data,tf.float32)*<span class="number">1</span>/(<span class="number">2</span>*mean)</span><br><span class="line">    <span class="keyword">return</span> tf.reshape(data,[<span class="number">-1</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">MEANS = &#123;</span><br><span class="line">    <span class="string">'age'</span> : <span class="number">29.631308</span>,</span><br><span class="line">    <span class="string">'n_siblings_spouses'</span> : <span class="number">0.545455</span>,</span><br><span class="line">    <span class="string">'parch'</span> : <span class="number">0.379585</span>,</span><br><span class="line">    <span class="string">'fare'</span> : <span class="number">34.385399</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">numerical_columns=[]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> MEANS.keys():</span><br><span class="line">    num_col=tf.feature_column.numeric_column(</span><br><span class="line">        feature,</span><br><span class="line">        normalizer_fn=functools.partial(process_continuous_data,MEANS[feature]))</span><br><span class="line">    numerical_columns.append(num_col)</span><br><span class="line"></span><br><span class="line">print(numerical_columns)</span><br><span class="line"></span><br><span class="line">preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numerical_columns)</span><br><span class="line"></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    preprocessing_layer,</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>),<span class="comment"># 基于特征层的基础上构建全连接层</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>)<span class="comment"># 最后只需要预测一个结果</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    loss=<span class="string">'binary_crossentropy'</span>,<span class="comment"># 定义损失函数</span></span><br><span class="line">    optimizer=<span class="string">'adam'</span>,<span class="comment"># 定义优化器</span></span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])<span class="comment"># 定义衡量结果的标准</span></span><br><span class="line">	</span><br><span class="line">train_data=raw_train_data.shuffle(<span class="number">500</span>) <span class="comment"># 打乱数据</span></span><br><span class="line">test_data=raw_test_data</span><br><span class="line"></span><br><span class="line">model.fit(train_data,epochs=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">test_loss, test_accuracy = model.evaluate(test_data) <span class="comment"># 测试模型</span></span><br><span class="line">print(test_loss)</span><br><span class="line">print(test_accuracy)</span><br></pre></td></tr></table></figure>
<h4 id="pandas处理数据版泰坦尼克生存预测模型完整代码"><a href="#pandas处理数据版泰坦尼克生存预测模型完整代码" class="headerlink" title="pandas处理数据版泰坦尼克生存预测模型完整代码"></a>pandas处理数据版泰坦尼克生存预测模型完整代码</h4><p>私以为这个版本比上面那个版本更容易理解一些，不过在处理特征上的区别不是很大。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line">train_file=<span class="string">'./dataset/train.csv'</span></span><br><span class="line">eval_file=<span class="string">'./dataset/eval.csv'</span></span><br><span class="line"></span><br><span class="line">train_df=pd.read_csv(train_file)</span><br><span class="line">eval_df=pd.read_csv(eval_file)</span><br><span class="line"></span><br><span class="line">print(train_df.head())</span><br><span class="line">print(eval_df.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取出survived字段作为label</span></span><br><span class="line">y_train=train_df.pop(<span class="string">'survived'</span>)</span><br><span class="line">y_eval=eval_df.pop(<span class="string">'survived'</span>)</span><br><span class="line"></span><br><span class="line">print(y_train.head())</span><br><span class="line">print(y_eval.head())</span><br><span class="line"></span><br><span class="line">print(train_df.shape)</span><br><span class="line">print(eval_df.shape)</span><br><span class="line"></span><br><span class="line">feature_columns=[]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理离散型特征</span></span><br><span class="line">categorical_columns=[<span class="string">'sex'</span>,<span class="string">'n_siblings_spouses'</span>,<span class="string">'parch'</span>,</span><br><span class="line">    <span class="string">'class'</span>,<span class="string">'deck'</span>,<span class="string">'embark_town'</span>,<span class="string">'alone'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> categorical_column <span class="keyword">in</span> categorical_columns:</span><br><span class="line">    <span class="comment"># 取出离散型特征对应的值并去重</span></span><br><span class="line">    vocab=train_df[categorical_column].unique()</span><br><span class="line">    <span class="comment"># 使用 tensorflow 来定义离散特征 categorical_column_with_vocabulary_list</span></span><br><span class="line">    <span class="comment"># tf 生成离散型特征需要两个参数,特征名和特征值</span></span><br><span class="line">    <span class="comment"># tf 生成 one-hot 编码:indicator_column</span></span><br><span class="line">    print(categorical_column,vocab)</span><br><span class="line">    feature_columns.append(tf.feature_column.indicator_column(</span><br><span class="line">        tf.feature_column.categorical_column_with_vocabulary_list(</span><br><span class="line">            categorical_column,vocab)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理连续型特征</span></span><br><span class="line">numeric_columns=[<span class="string">'age'</span>,<span class="string">'fare'</span>]</span><br><span class="line"><span class="keyword">for</span> numeric_column <span class="keyword">in</span> numeric_columns:</span><br><span class="line">    print(numeric_column)</span><br><span class="line">    feature_columns.append(tf.feature_column.numeric_column(numeric_column,dtype=tf.float32))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'feature_columns:\n'</span>,feature_columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 制作数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_dataset</span><span class="params">(data_df,label,epochs=<span class="number">10</span>,shuffle=True,batch_size=<span class="number">32</span>)</span>:</span></span><br><span class="line">    dataset=tf.data.Dataset.from_tensor_slices(</span><br><span class="line">        (dict(data_df),label))</span><br><span class="line">    <span class="keyword">if</span> shuffle:<span class="comment"># 是否打乱数据集</span></span><br><span class="line">        dataset=dataset.shuffle(<span class="number">10000</span>)</span><br><span class="line">    <span class="comment"># 设置数据集需要迭代的次数</span></span><br><span class="line">    dataset=dataset.repeat(epochs).batch(batch_size)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line">	</span><br><span class="line">model=keras.models.Sequential([</span><br><span class="line">    keras.layers.DenseFeatures(feature_columns),</span><br><span class="line">    keras.layers.Dense(<span class="number">100</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">100</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">2</span>,activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment"># tf2.1.0的版本里如果不单独设置，则默认sdg=0.01，这样收敛太快容易找不到对应的值，所以手动调一下</span></span><br><span class="line">sgd=keras.optimizers.SGD(<span class="number">0.001</span>)</span><br><span class="line">model.compile(</span><br><span class="line">    loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    optimizer=sgd,</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">	</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line">train_dataset=make_dataset(train_df,y_train,epochs=<span class="number">100</span>)</span><br><span class="line">eval_dataset=make_dataset(eval_df,y_eval,epochs=<span class="number">1</span>,shuffle=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># steps_per_epoch:训练集中样本数/batch_size</span></span><br><span class="line"><span class="comment"># validation_steps:验证集中样本数/batch_size</span></span><br><span class="line">model.fit(</span><br><span class="line">    train_dataset,</span><br><span class="line">    steps_per_epoch=<span class="number">15</span>,</span><br><span class="line">    epochs=<span class="number">100</span>)</span><br><span class="line">	</span><br><span class="line"><span class="comment"># 验证模型</span></span><br><span class="line">loss,acc=model.evaluate(eval_dataset)</span><br><span class="line">print(<span class="string">'loss:'</span>,loss)</span><br><span class="line">print(<span class="string">'acc:'</span>,acc)</span><br></pre></td></tr></table></figure>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>构建可以在模型中进行训练的数据集主要有两种方式:</p>
<ol>
<li>使用 tf.data.experimental.make_csv_dataset 来设置；</li>
<li>使用 tf.data.Dataset.from_tensor_slices，将数据和标签合并为一个元组来创建数据集。</li>
</ol>
<h3 id="numpy数据预处理"><a href="#numpy数据预处理" class="headerlink" title="numpy数据预处理"></a>numpy数据预处理</h3><p>这类数据的类型.npz,需要通过 np,load()函数来进行加载。<br>数据集下载地址：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http<span class="variable">s:</span>//storage.googleapis.<span class="keyword">com</span>/tensorflow/<span class="keyword">tf</span>-keras-datasets/mnist.npz</span><br></pre></td></tr></table></figure></p>
<p>这个可以说是比较简单的处理方式了，和上面csv的区别仅在于要用到np.load函数。<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow_datasets as tfds</span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入数据</span></span><br><span class="line">dataset=np.load('./dataset/mnist.npz')</span><br><span class="line">train_examples=dataset['x_train']</span><br><span class="line">train_labels=dataset['y_train']</span><br><span class="line">test_examples=dataset['x_test']</span><br><span class="line">test_labels=dataset['y_test']</span><br><span class="line"></span><br><span class="line">print(train_examples.shape)</span><br><span class="line">print(train_labels.shape)</span><br><span class="line">print(test_examples.shape)</span><br><span class="line">print(test_labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 tf.data.Dataset加载numpy数组</span></span><br><span class="line"></span><br><span class="line">train_dataset=tf.data.Dataset.from_tensor_slices((train_examples,train_labels))</span><br><span class="line">test_dataset=tf.data.Dataset.from_tensor_slices((test_examples,test_labels))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置数据集的epochs和batch_size</span></span><br><span class="line">batch_size=32</span><br><span class="line">epochs=10</span><br><span class="line">shuffle=10000</span><br><span class="line"></span><br><span class="line">train_dataset=train_dataset.repeat(epochs).batch(batch_size).shuffle(shuffle)</span><br><span class="line">test_dataset=test_dataset.repeat(1).batch(batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型的构建和训练</span></span><br><span class="line"></span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(28,28)),</span><br><span class="line">    tf.keras.layers.Dense(128,activation='relu'),</span><br><span class="line">    tf.keras.layers.Dense(10,activation='softmax')<span class="comment"># 最后的分类概率</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=tf.keras.optimizers.RMSprop(),</span><br><span class="line">    loss=tf.keras.losses.SparseCategoricalCrossentropy(),</span><br><span class="line">    metrics=[tf.keras.metrics.SparseCategoricalCrossentropy()])</span><br><span class="line">	</span><br><span class="line">model.fit(</span><br><span class="line">    train_dataset,</span><br><span class="line">    epochs=10)<span class="comment"># 这个训练耗时比较长...</span></span><br><span class="line">	</span><br><span class="line">model.evaluate(test_dataset)</span><br></pre></td></tr></table></figure></p>
<p>至于pandas数据，上面在方式二中已经写过，不再赘述。</p>
<h3 id="图像数据处理"><a href="#图像数据处理" class="headerlink" title="图像数据处理"></a>图像数据处理</h3><p>讲真，看到这块的时候我心情有点复杂，想当年我入坑NLP的时候信誓旦旦的说这辈子绝对不碰cv相关。<br>鬼知道怎么就半只脚踏入了VQA的坑…行吧，那图像处理也得学。</p>
<p>这里使用的数据集下载地址：<br><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">https:</span>//storage.googleapis.com/download.tensorflow<span class="meta">.org</span>/example_images/flower_photos.tgz</span><br></pre></td></tr></table></figure></p>
<p>以及，对于图像分类的例子，可以直接去Kaggle上看那个10-monkeys的例子。</p>
<p>图像处理这块只针对数据的预处理，后续在CNN搭建的过程中会详细描述如何将数据输入神经网络。</p>
<p>老规矩，首先把数据集下载下来,然后存到所需文件夹下面（以下代码格式以Jupyter模式为例）<br><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"></span><br><span class="line">data_root_orig=<span class="string">'dataset/flower_photos'</span></span><br><span class="line">data_root=pathlib.Path(data_root_orig)</span><br></pre></td></tr></table></figure></p>
<p>pathlib是用来加载路径的，具体用法可参考：<a href="https://docs.python.org/zh-cn/3/library/pathlib.html" target="_blank" rel="noopener">https://docs.python.org/zh-cn/3/library/pathlib.html</a></p>
<p>查看不同类型的花花所在的文件夹:<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">item</span> <span class="keyword">in</span> data_root.iterdir():</span><br><span class="line">    print(<span class="built_in">item</span>)</span><br></pre></td></tr></table></figure></p>
<p>输出结果:<br><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>aisy</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>andelion</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\L</span>ICENSE.txt</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\r</span>oses</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\s</span>unflowers</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\t</span>ulips</span><br></pre></td></tr></table></figure></p>
<p>打乱数据操作:<br><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import <span class="built_in">random</span></span><br><span class="line"></span><br><span class="line">all_image_paths=list(data_root.glob(<span class="string">'*/*'</span>))</span><br><span class="line">all_image_paths=[str(<span class="built_in">path</span>) <span class="keyword">for</span> <span class="built_in">path</span> <span class="keyword">in</span> all_image_paths]</span><br><span class="line"><span class="built_in">random</span>.shuffle(all_image_paths) # 打乱顺序</span><br><span class="line"></span><br><span class="line">image_count=<span class="built_in">len</span>(all_image_paths)</span><br><span class="line"><span class="built_in">print</span>(image_count)# 打印出图片数量,共有<span class="number">3670</span>张</span><br></pre></td></tr></table></figure></p>
<p>输出:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3670</span></span><br></pre></td></tr></table></figure></p>
<p>查看all_image_paths中的数据格式:<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(('.\n').join(<span class="name">all_image_paths</span>[:<span class="number">10</span>]))</span><br></pre></td></tr></table></figure></p>
<p>输出结果:<br><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\s</span>unflowers<span class="symbol">\1</span>5266715291_dfa3f1d49f_n.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>andelion<span class="symbol">\4</span>634716478_1cbcbee7ca.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>aisy<span class="symbol">\1</span>392946544_115acbb2d9.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\s</span>unflowers<span class="symbol">\6</span>250692311_cb60c85ee9_n.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\r</span>oses<span class="symbol">\3</span>494252600_29f26e3ff0_n.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>andelion<span class="symbol">\5</span>607256228_2294c201b3.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\t</span>ulips<span class="symbol">\1</span>4027372499_30f934d24f_m.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\d</span>aisy<span class="symbol">\3</span>773181799_5def396456.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\t</span>ulips<span class="symbol">\1</span>6862349256_0a1f91ab53.jpg.</span><br><span class="line">dataset<span class="symbol">\f</span>lower_photos<span class="symbol">\s</span>unflowers<span class="symbol">\1</span>8843967474_9cb552716b.jpg</span><br></pre></td></tr></table></figure></p>
<p>检查图片,在处理之前需要知道图片的内容:<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">attributions = (data_root/<span class="string">"LICENSE.txt"</span>).<span class="keyword">open</span>(encoding='utf-8').readlines()[4:] # 这个文件包含了所有图片的说明</span><br><span class="line">attributions = [<span class="keyword">line</span>.<span class="keyword">split</span>(' <span class="keyword">CC</span>-<span class="keyword">BY</span> ') <span class="keyword">for</span> <span class="keyword">line</span> <span class="keyword">in</span> attributions]</span><br><span class="line">attributions = dict(attributions)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> attributions.items():</span><br><span class="line">    <span class="keyword">print</span>(x)</span><br><span class="line">    <span class="keyword">print</span>(y)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure></p>
<p>输出值如下：<br><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">daisy/<span class="number">7568630428</span>_8cf0fc16ff_n.jpg </span><br><span class="line"> by <span class="keyword">A</span> Guy Taking Pictures - https://www.flickr.com/photos/<span class="number">80901381</span>@N04/<span class="number">7568630428</span>/</span><br></pre></td></tr></table></figure></p>
<p>取出图片并展示：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import IPython.<span class="keyword">display</span> <span class="keyword">as</span> <span class="keyword">display</span></span><br><span class="line"></span><br><span class="line">def caption_image(image_path):</span><br><span class="line">    #print(image_path)</span><br><span class="line">    image_rel = pathlib.Path(image_path).relative_to(data_root)</span><br><span class="line">    <span class="keyword">print</span>(image_rel)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">res</span>=<span class="string">"Image (CC BY 2.0) "</span> + <span class="string">' - '</span>.<span class="keyword">join</span>(attributions[str(image_rel)][:-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">res</span></span><br><span class="line">    except Exception <span class="keyword">as</span> <span class="keyword">e</span>:</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> n in <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">  image_path = random.choice(all_image_paths)</span><br><span class="line">  <span class="keyword">display</span>.<span class="keyword">display</span>(<span class="keyword">display</span>.Image(image_path))</span><br><span class="line">  <span class="keyword">print</span>(caption_image(image_path))</span><br><span class="line">  <span class="keyword">print</span>()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/28/JhfbUe.png" alt=""></p>
<p>众所周知，一个数据集由x和label组成，在这组花类别数据集中，label就是花的类别，每种不同类别的花被单独放在不同的文件夹里面。<br>现在把这些label取出来进行排序并编号。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">label_names=sorted(item<span class="selector-class">.name</span> <span class="keyword">for</span> item <span class="keyword">in</span> data_root.glob(<span class="string">'*/'</span>) <span class="keyword">if</span> item.is_dir())</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(label_names)</span></span></span><br></pre></td></tr></table></figure></p>
<p>输出值如下：<br><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">'daisy</span>', <span class="symbol">'dandelion</span>', <span class="symbol">'roses</span>', <span class="symbol">'sunflowers</span>', <span class="symbol">'tulips</span>']</span><br></pre></td></tr></table></figure></p>
<p>为每个标签分配索引值（即编号）：<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">label_to_index=dict((<span class="name">name</span>,index) for index,name in enumerate(<span class="name">label_names</span>))</span><br><span class="line">print(<span class="name">label_to_index</span>)</span><br></pre></td></tr></table></figure></p>
<p>输出值如下：<br><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'daisy'</span>: <span class="number">0</span>, <span class="string">'dandelion'</span>: <span class="number">1</span>, <span class="string">'roses'</span>: <span class="number">2</span>, <span class="string">'sunflowers'</span>: <span class="number">3</span>, <span class="string">'tulips'</span>: <span class="number">4</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>完成label的创建，需要把label对应给不同的图片构成一个相应的标签集合。<br>注意：这里的数据是先前已经打乱过的。<br><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">all_image_labels=[label_to_index[pathlib.<span class="built_in">Path</span>(<span class="built_in">path</span>).parent.name] # 取出当前图片的父级目录</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">path</span> <span class="keyword">in</span> all_image_paths]</span><br><span class="line"><span class="built_in">print</span>(all_image_labels)</span><br><span class="line"><span class="built_in">print</span>(len(all_image_labels))</span><br></pre></td></tr></table></figure></p>
<p>所以现在的图片和label就是一一对应的。<br><img src="https://s1.ax1x.com/2020/04/28/JhhmrV.png" alt=""></p>
<p>完成x和label的整理，现在需要将这些数据处理为tf模型可以训练的形式。<br>这就需要一个函数 <b> tf.io.read_file </b>.<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取出一条单独的数据作示范</span></span><br><span class="line"><span class="attribute">img_path</span>=all_image_paths[0]</span><br><span class="line"><span class="attribute">img_raw</span>=tf.io.read_file(img_path)</span><br><span class="line"><span class="builtin-name">print</span>(repr(img_raw)[:100])</span><br></pre></td></tr></table></figure></p>
<p><img src="https://s1.ax1x.com/2020/04/28/Jhh82R.png" alt=""></p>
<p>在此基础上将图片解码为图像tensor:<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">img_tensor=tf<span class="selector-class">.image</span><span class="selector-class">.decode_image</span>(img_raw)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(img_tensor.shape)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(img_tensor.dtype)</span></span></span><br></pre></td></tr></table></figure></p>
<p>输出值如下：<br><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">259</span>, <span class="number">320</span>, <span class="number">3</span>)</span><br><span class="line">&lt;d<span class="keyword">type</span>: 'uint8'&gt;</span><br></pre></td></tr></table></figure></p>
<p>从上面的输出中可以看出，每张图片的大小是不一致的，但是模型需要大小一致的矩阵合集作为输入，所以需要人工调节图片大小。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据模型调整输入大小</span></span><br><span class="line"><span class="attribute">img_final</span>=tf.image.resize(img_tensor,[192,192])</span><br><span class="line"><span class="comment"># 对每个像素进行处理</span></span><br><span class="line"><span class="attribute">img_final</span>=img_final/255.0</span><br><span class="line"><span class="builtin-name">print</span>(img_final.shape)</span><br><span class="line"><span class="builtin-name">print</span>(img_final.numpy().min())</span><br><span class="line"><span class="builtin-name">print</span>(img_final.numpy().max())</span><br></pre></td></tr></table></figure></p>
<p>输出结果：<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">192</span>, <span class="number">192</span>, <span class="number">3</span>)</span><br><span class="line"><span class="number">0.0</span></span><br><span class="line"><span class="number">0.98491627</span></span><br></pre></td></tr></table></figure></p>
<p>为了方便处理每张图片时不需要重复写代码，可以将上述操作封装为函数。<br><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 处理图像</span><br><span class="line">def preprocess_image(<span class="built_in">image</span>):</span><br><span class="line">    <span class="built_in">image</span>=tf.<span class="built_in">image</span>.decode_jpeg(<span class="built_in">image</span>,channels=<span class="number">3</span>)</span><br><span class="line">    <span class="built_in">image</span>=tf.<span class="built_in">image</span>.resize(<span class="built_in">image</span>,[<span class="number">192</span>,<span class="number">192</span>])</span><br><span class="line">    <span class="built_in">image</span>/=<span class="number">255.0</span> # 将数值归一化在 [<span class="number">0</span>,<span class="number">1</span>]区间</span><br><span class="line">    <span class="built_in">return</span> <span class="built_in">image</span></span><br><span class="line">	</span><br><span class="line"># 加载并处理图像</span><br><span class="line">def load_and_preprocess_image(path):</span><br><span class="line">    <span class="built_in">image</span>=tf.io.read_file(path)</span><br><span class="line">    <span class="built_in">return</span> preprocess_image(<span class="built_in">image</span>)</span><br></pre></td></tr></table></figure></p>
<p>OK，正式开始调用 <b>tf.data.Dataset.from_tensor_slices</b> 构造数据集。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">path_ds</span>=tf.data.Dataset.from_tensor_slices(all_image_paths)</span><br><span class="line"><span class="builtin-name">print</span>(path_ds)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个新的数据集,通过在路径数据集上映射preprocess_image来动态加载和格式化图片</span></span><br><span class="line"><span class="attribute">AUTOTUNE</span>=tf.data.experimental.AUTOTUNE</span><br><span class="line"><span class="comment"># 数据块</span></span><br><span class="line"><span class="attribute">image_ds</span>=path_ds.map(load_and_preprocess_image,num_parallel_calls=AUTOTUNE)</span><br><span class="line"><span class="comment"># 标签块</span></span><br><span class="line"><span class="attribute">label_ds</span>=tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels,tf.int64))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试取出的labels</span></span><br><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> label_ds.take(10):</span><br><span class="line">    <span class="builtin-name">print</span>(label_names[label.numpy()])</span><br></pre></td></tr></table></figure>
<p><img src="https://s1.ax1x.com/2020/04/28/Jh4lef.png" alt=""></p>
<p>对数据集进行打包（对x和label进行concate），tf框架提供了两种打包方式：</p>
<ol>
<li><b>tf.data.Dataset.zip</b><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_label_ds=tf<span class="selector-class">.data</span><span class="selector-class">.Dataset</span><span class="selector-class">.zip</span>((image_ds,label_ds))</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(image_label_ds)</span></span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><img src="https://s1.ax1x.com/2020/04/28/Jh4ayq.png" alt=""></p>
<ol>
<li><b>tf.data.Dataset.from_tensor_slices</b><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ds=tf.data.Dataset.from_tensor_slices((all_image_paths,all_image_labels))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 元组被解压缩到映射函数的位置参数中</span></span><br><span class="line">def load_and_preprocess_from_path_label(path,<span class="keyword">label</span><span class="bash">):</span></span><br><span class="line"><span class="bash">    <span class="built_in">return</span> load_and_preprocess_image(path),label</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">image_label_ds=ds.map(load_and_preprocess_from_path_label)</span></span><br><span class="line"><span class="bash"><span class="built_in">print</span>(image_label_ds)</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><img src="https://s1.ax1x.com/2020/04/28/Jh46fJ.png" alt=""></p>
<p>至此，完成数据集制作只需要设置完数据的batch_size,epochs，shuffle等参数即可。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">batch_size</span>=32</span><br><span class="line"><span class="attribute">shuffle_size</span>=3670</span><br><span class="line"><span class="attribute">epochs</span>=10</span><br><span class="line"><span class="comment"># 设置一个和数据集大小一致的shuffle buffer size来保证数据被充分打乱</span></span><br><span class="line"><span class="comment"># 另外,如果buffer_size设置过大，会引起延迟</span></span><br><span class="line"><span class="attribute">ds</span>=image_label_ds.shuffle(shuffle_size)</span><br><span class="line"><span class="comment"># 注意:先repeat再batch</span></span><br><span class="line"><span class="attribute">ds</span>=ds.repeat(epochs).batch(batch_size)</span><br><span class="line"><span class="builtin-name">print</span>(ds)</span><br></pre></td></tr></table></figure></p>
<p>图片数据处理部分结束。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/04/26/TensorFlow-2-0-使用指南/" data-id="ck9iph7bn0027wcv4ax7zfae0" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2020/04/14/【统计自然语言处理】形式语言与自动机/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Älter</strong>
      <div class="article-nav-title">【统计自然语言处理】形式语言与自动机</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    <div class="widget-wrap">
    <h3 class="widget-title">联系方式</h3>
    <div class="widget">
	  <li><a>klausvon@163.com</a></li>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">目录</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AI-Learning/">AI_Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CTF/">CTF</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HTML/">HTML</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP-知识图谱/">NLP,知识图谱</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/VQA/">VQA</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/XSS漏洞学习/">XSS漏洞学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/代码审计/">代码审计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发/">开发</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数学学习/">数学学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/漏洞学习/">漏洞学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境配置/">环境配置</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/神经网络/">神经网络</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CTF-Web/">CTF_Web</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HTML/">HTML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaScript/">JavaScript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PHP/">PHP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQL-injection/">SQL_injection</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VQA/">VQA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XXE/">XXE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/凸包算法/">凸包算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/开发/">开发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数学学习/">数学学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据挖掘/">数据挖掘</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/环境配置/">环境配置</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/知识图谱/">知识图谱</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/神经网络/">神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法考核/">算法考核</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithm/" style="font-size: 14.29px;">Algorithm</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/CTF-Web/" style="font-size: 18.57px;">CTF_Web</a> <a href="/tags/HTML/" style="font-size: 10px;">HTML</a> <a href="/tags/JavaScript/" style="font-size: 10px;">JavaScript</a> <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/PHP/" style="font-size: 10px;">PHP</a> <a href="/tags/Python/" style="font-size: 11.43px;">Python</a> <a href="/tags/SQL-injection/" style="font-size: 12.86px;">SQL_injection</a> <a href="/tags/VQA/" style="font-size: 10px;">VQA</a> <a href="/tags/XXE/" style="font-size: 10px;">XXE</a> <a href="/tags/凸包算法/" style="font-size: 10px;">凸包算法</a> <a href="/tags/大数据/" style="font-size: 11.43px;">大数据</a> <a href="/tags/开发/" style="font-size: 12.86px;">开发</a> <a href="/tags/数学学习/" style="font-size: 11.43px;">数学学习</a> <a href="/tags/数据挖掘/" style="font-size: 11.43px;">数据挖掘</a> <a href="/tags/环境配置/" style="font-size: 10px;">环境配置</a> <a href="/tags/知识图谱/" style="font-size: 17.14px;">知识图谱</a> <a href="/tags/神经网络/" style="font-size: 15.71px;">神经网络</a> <a href="/tags/算法/" style="font-size: 10px;">算法</a> <a href="/tags/算法考核/" style="font-size: 10px;">算法考核</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">October 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/04/26/TensorFlow-2-0-使用指南/">TensorFlow 2.0 使用指南 (2020.4.27更新图片数据处理块)</a>
          </li>
        
          <li>
            <a href="/2020/04/14/【统计自然语言处理】形式语言与自动机/">【统计自然语言处理】形式语言与自动机</a>
          </li>
        
          <li>
            <a href="/2020/04/09/【论文笔记】Preemptive-Information-Extraction-using-Unrestricted-Relation-Discovery/">【论文笔记】Preemptive Information Extraction using Unrestricted Relation Discovery</a>
          </li>
        
          <li>
            <a href="/2020/04/07/【论文笔记】Semantic-Compositionality-through-Recursive-Matrix-Vector-Spaces/">【论文笔记】Semantic Compositionality through Recursive Matrix-Vector Spaces</a>
          </li>
        
          <li>
            <a href="/2020/04/06/【论文笔记】Discovering-Relations-among-Named-Entities-from-Large-Corpora/">【论文笔记】Discovering Relations among Named Entities from Large Corpora</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    <div class="widget-wrap">
    <h3 class="widget-title">友情链接</h3>
    <div class="widget">
	  <li><a href="http://030.im/" title="Misaka030">Misaka030</a></li>
      <li><a href="http://cicisite.me/" title="cici's blog">cici</a></li>
	  <li><a href="http://guoxiaobo.com/" title="Guo Sir">Guo Sir</a></li>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Klaus<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>